invPref_baseline = notEvery_logProb - none_logProb)
scores.all <- scores.all %>%
rename(invPref_human = estimate)
scores.all.pivot <- scores.all %>%
pivot_longer(
cols = c(invPref_inContext, invPref_baseline),
names_to = "invPref_type",
values_to = "invPref",
names_pattern = "context"
)
library(tidyverse)
library(lme4)
library(ggpubr)
library(lmtest)
library(patchwork)
scores.inContext <- read_csv('EveryNeg_inContext_logProbs_miniconsGPT2_ThisMeansThat.csv')
scores.woContext <- read_csv('EveryNeg_woContext_logProbs_miniconsGPT2_ThisMeansThat.csv')
scores.all <- cbind(scores.inContext,scores.woContext[,c('none_logProb','notEvery_logProb')])
scores.all <- scores.all %>%
mutate(invPref_inContext = notEvery_inContext_logProb - none_inContext_logProb,
invPref_baseline = notEvery_logProb - none_logProb)
scores.all <- scores.all %>%
rename(invPref_human = estimate)
scores.all.pivot <- scores.all %>%
pivot_longer(
cols = c(invPref_inContext, invPref_baseline),
names_to = "invPref_type",
values_to = "invPref",
names_pattern = "context"
)
library(ggpubr)
library(tidyverse)
library(lme4)
library(ggpubr)
library(lmtest)
library(patchwork)
scores.inContext <- read_csv('EveryNeg_inContext_logProbs_miniconsGPT2_ThisMeansThat.csv')
scores.woContext <- read_csv('EveryNeg_woContext_logProbs_miniconsGPT2_ThisMeansThat.csv')
scores.all <- cbind(scores.inContext,scores.woContext[,c('none_logProb','notEvery_logProb')])
scores.all <- scores.all %>%
mutate(invPref_inContext = notEvery_inContext_logProb - none_inContext_logProb,
invPref_baseline = notEvery_logProb - none_logProb)
scores.all <- scores.all %>%
rename(invPref_human = estimate)
scores.all.pivot <- scores.all %>%
pivot_longer(
cols = c(invPref_inContext, invPref_baseline),
names_to = "context",
values_to = "invPref",
names_pattern = "invPref_(.*)"
)
ggplot(scores.all.pivot, aes(x=invPref,y=invPref_human,color=context)) +
geom_point(alpha = 0.1) +
geom_smooth(method='lm') +
stat_cor(method='pearson',size=10) +
ylab("Human inverse preference") +
xlab("LM inverse preference") +
theme_classic() +
theme(
text = element_text(size = 25),         # General text size
axis.title = element_text(size = 25),   # Axis titles
axis.text = element_text(size = 25),    # Axis text
legend.text = element_text(size = 25),  # Legend text
legend.title = element_text(size = 25)  # Legend title
)
ggplot(scores.all.pivot, aes(x=invPref,y=invPref_human,color=context)) +
geom_point(alpha = 0.1) +
geom_smooth(method='lm') +
stat_cor(method='pearson',size=10,show.legend = FALSE) +
ylab("Human inverse preference") +
xlab("LM inverse preference") +
theme_classic() +
theme(
text = element_text(size = 25),         # General text size
axis.title = element_text(size = 25),   # Axis titles
axis.text = element_text(size = 25),    # Axis text
legend.text = element_text(size = 25),  # Legend text
legend.title = element_text(size = 25)  # Legend title
)
library(tidyverse)
library(lme4)
library(ggpubr)
library(lmtest)
library(patchwork)
scores.inContext <- read_csv('EveryNeg_inContext_logProbs_miniconsGPT2_ThisMeansThat.csv')
scores.woContext <- read_csv('EveryNeg_woContext_logProbs_miniconsGPT2_ThisMeansThat.csv')
scores.all <- cbind(scores.inContext,scores.woContext[,c('none_logProb','notEvery_logProb')])
scores.all <- scores.all %>%
mutate(invPref_inContext = notEvery_inContext_logProb - none_inContext_logProb,
invPref_baseline = notEvery_logProb - none_logProb)
scores.all <- scores.all %>%
rename(invPref_human = estimate)
scores.all.pivot <- scores.all %>%
pivot_longer(
cols = c(invPref_inContext, invPref_baseline),
names_to = "Type",
values_to = "invPref",
names_pattern = "invPref_(.*)"
)
ggplot(scores.all.pivot, aes(x=invPref,y=invPref_human,color=context)) +
geom_point(alpha = 0.1) +
geom_smooth(method='lm') +
stat_cor(method='pearson',size=10,show.legend = FALSE) +
ylab("Human inverse preference") +
xlab("LM inverse preference") +
theme_classic() +
theme(
text = element_text(size = 25),         # General text size
axis.title = element_text(size = 25),   # Axis titles
axis.text = element_text(size = 25),    # Axis text
legend.text = element_text(size = 25),  # Legend text
legend.title = element_text(size = 25)  # Legend title
)
library(tidyverse)
library(lme4)
library(ggpubr)
library(lmtest)
library(patchwork)
scores.inContext <- read_csv('EveryNeg_inContext_logProbs_miniconsGPT2_ThisMeansThat.csv')
scores.woContext <- read_csv('EveryNeg_woContext_logProbs_miniconsGPT2_ThisMeansThat.csv')
scores.all <- cbind(scores.inContext,scores.woContext[,c('none_logProb','notEvery_logProb')])
scores.all <- scores.all %>%
mutate(invPref_inContext = notEvery_inContext_logProb - none_inContext_logProb,
invPref_baseline = notEvery_logProb - none_logProb)
scores.all <- scores.all %>%
rename(invPref_human = estimate)
scores.all.pivot <- scores.all %>%
pivot_longer(
cols = c(invPref_inContext, invPref_baseline),
names_to = "Type",
values_to = "invPref",
names_pattern = "invPref_(.*)"
)
ggplot(scores.all.pivot, aes(x=invPref,y=invPref_human,color=Type)) +
geom_point(alpha = 0.1) +
geom_smooth(method='lm') +
stat_cor(method='pearson',size=10,show.legend = FALSE) +
ylab("Human inverse preference") +
xlab("LM inverse preference") +
theme_classic() +
theme(
text = element_text(size = 25),         # General text size
axis.title = element_text(size = 25),   # Axis titles
axis.text = element_text(size = 25),    # Axis text
legend.text = element_text(size = 25),  # Legend text
legend.title = element_text(size = 25)  # Legend title
)
scores.all.pivot <- scores.all.pivot %>%
mutate(Type = case_when(
Type == "baseline" ~ "Baseline",
Type == "inContext" ~ "In context"
))
ggplot(scores.all.pivot, aes(x=invPref,y=invPref_human,color=Type)) +
geom_point(alpha = 0.1) +
geom_smooth(method='lm') +
stat_cor(method='pearson',size=10,show.legend = FALSE) +
ylab("Human inverse preference") +
xlab("LM inverse preference") +
theme_classic() +
theme(
text = element_text(size = 25),         # General text size
axis.title = element_text(size = 25),   # Axis titles
axis.text = element_text(size = 25),    # Axis text
legend.text = element_text(size = 25),  # Legend text
legend.title = element_text(size = 25)  # Legend title
)
ggplot(scores.all.pivot, aes(x=invPref,y=invPref_human,color=Type)) +
geom_point(alpha = 0.1) +
geom_smooth(method='lm') +
stat_cor(method='pearson',size=10,show.legend = FALSE) +
ylab("Human inverse preference") +
xlab("LM inverse preference") +
theme_classic() +
guides(color = guide_legend(title = NULL)) +
theme(
text = element_text(size = 25),         # General text size
axis.title = element_text(size = 25),   # Axis titles
axis.text = element_text(size = 25),    # Axis text
legend.text = element_text(size = 25),  # Legend text
legend.title = element_text(size = 25)  # Legend title
)
setwd("~/Desktop/contextual-predictability-speaker-choices")
library(tidyverse)
library(lme4)
library(ggsignif)
library(ggpubr)
library(lmtest)
library(patchwork)
library(cowplot)
library(emmeans)
library(relaimpo)
library(partR2)
library(ggeffects)
library(lmerTest)
library(dominanceanalysis)
library(tidyverse)
library(lme4)
library(ggsignif)
library(ggpubr)
library(lmtest)
library(patchwork)
library(cowplot)
library(emmeans)
library(relaimpo)
library(partR2)
library(ggeffects)
library(lmerTest)
library(dominanceanalysis)
scores <- read_csv('SWBD_DurAnalysisData.csv')
setwd("~/Desktop/contextual-predictability-speaker-choices/Study1-probabilistic-reduction")
scores <- read_csv('SWBD_DurAnalysisData.csv')
scores <- scores %>% filter(Class != 'OTHER')
scores$Class <- factor(scores$Class, levels = c('Function','Content'))
# define backward predictability variants
scores$delta_bwPred <- scores$infillBw_logProb - scores$infillFw_logProb
scores <- scores %>% rename(condPMI = infill_pmiFP)
# analysis of function versus content words
HF_func_words <- c('i','and','the','that','a','to','you','of','it','in')
scores <- scores %>%
mutate(lexical_category = case_when(
Class == 'Content'~ 'Content',
Class == 'Function' & word %in% HF_func_words ~ 'High-Freq-Function',
Class == 'Function' & !(word %in% HF_func_words) ~ 'Mid-to-Low-Freq-Function'
))
scores %>%
group_by(lexical_category) %>%
count()
##  main effect of func-content words
m.FuncContentDist.mainEffect.deltaBwPred <- lmer(duration * 1000 ~ word_len + uttrSR + age + sex + unigram_logProb + infillFw_logProb + delta_bwPred + Class + (1|speaker_id), data = scores)
summary(m.FuncContentDist.mainEffect.deltaBwPred)
## interaction
m.FuncContentDist.int.deltaBwPred <- lmer(duration * 1000 ~ word_len + uttrSR + age + sex + unigram_logProb * Class + infillFw_logProb * Class + delta_bwPred * Class + (1|speaker_id), data = scores)
summary(m.FuncContentDist.int.deltaBwPred)
## get simple means
emtrends(m.FuncContentDist.int.deltaBwPred, specs = "Class", var = "unigram_logProb",infer = c(TRUE, TRUE))
emtrends(m.FuncContentDist.int.deltaBwPred, specs = "Class", var = "infillFw_logProb",infer = c(TRUE, TRUE))
emtrends(m.FuncContentDist.int.deltaBwPred, specs = "Class", var = "delta_bwPred",infer = c(TRUE, TRUE))
### visualize
predict_interaction_with_ci <- function(model, x_var, group_var, n_points = 100,
nsim = 100, seed = 123) {
model_data <- model.frame(model)
# Error check
if (!all(c(x_var, group_var) %in% names(model_data))) {
stop("x_var and group_var must be in the model data.")
}
# Preserve factor levels as in the model
group_levels <- levels(model_data[[group_var]])
# Create a prediction grid
grid <- expand.grid(
x = seq(min(model_data[[x_var]], na.rm = TRUE),
max(model_data[[x_var]], na.rm = TRUE),
length.out = n_points),
group = factor(group_levels, levels = group_levels)
)
names(grid)[1:2] <- c(x_var, group_var)
# Fill in other predictors as average (or base level for factors)
all_vars <- all.vars(formula(model))
other_vars <- setdiff(all_vars, c(x_var, group_var, as.character(attr(terms(model), "response"))))
for (v in other_vars) {
if (!v %in% names(grid)) {
if (is.factor(model_data[[v]]) || is.character(model_data[[v]])) {
grid[[v]] <- factor(levels(model_data[[v]])[1], levels = levels(model_data[[v]]))
} else {
grid[[v]] <- mean(model_data[[v]], na.rm = TRUE)
}
}
}
# Define prediction function for bootMer
pred_fun <- function(fit) {
predict(fit, newdata = grid, re.form = NA)
}
set.seed(seed)
boot_results <- bootMer(
model,
pred_fun,
nsim = nsim,
type = "parametric",
use.u = FALSE,
verbose = FALSE
)
# Compute predictions and confidence intervals
predicted <- apply(boot_results$t, 2, mean)
ci_low <- apply(boot_results$t, 2, quantile, 0.025)
ci_high <- apply(boot_results$t, 2, quantile, 0.975)
output <- cbind(grid, predicted = predicted, ci_low = ci_low, ci_high = ci_high)
# Ensure group variable stays a factor with correct labels
output[[group_var]] <- factor(output[[group_var]], levels = group_levels)
return(output)
}
m.FuncContentDist.int.condPMI <- lmer(duration * 1000 ~ word_len + uttrSR + age + sex + unigram_logProb * Class + infillFw_logProb * Class + condPMI * Class + (1|speaker_id), data = scores)
summary(m.FuncContentDist.int.condPMI)
unigramPred_class <- predict_interaction_with_ci(
model = m.FuncContentDist.int.deltaBwPred,
x_var = "unigram_logProb",
group_var = "Class"
)
fwPred_class <- predict_interaction_with_ci(
model = m.FuncContentDist.mainEffect.deltaBwPred ,
x_var = "infillFw_logProb",
group_var = "Class"
)
deltaBwPred_class <- predict_interaction_with_ci(
model = m.FuncContentDist.mainEffect.deltaBwPred ,
x_var = "delta_bwPred",
group_var = "Class"
)
condPMI_class <- predict_interaction_with_ci(
model = m.FuncContentDist.mainEffect.condPMI ,
x_var = "condPMI",
group_var = "Class"
)
## visualizations
p1 <- ggplot(unigramPred_class, aes(x = unigram_logProb, y = predicted, color = Class, fill = Class)) +
geom_line() +
geom_ribbon(aes(ymin = ci_low, ymax = ci_high), alpha = 0.4, color = NA) +
labs(x = expression(bold("Log Unigram Predictability")), y = "") +
theme_minimal() +
#theme(legend.position = "none")  +
theme(axis.text.x = element_text(face = "bold", color = "black"),  # x-axis text
axis.text.y = element_text(face = "bold", color = "black"),  # y-axis text
axis.title.x = element_text(face = "bold", color = "black"),  # x-axis title
axis.title.y = element_text(face = "bold", color = "black"),  # y-axis title
plot.title = element_text(face = "bold", color = "black"),
legend.title = element_text(face = "bold"))
p2 <- ggplot(fwPred_class, aes(x = infillFw_logProb, y = predicted, color = Class, fill = Class)) +
geom_line() +
geom_ribbon(aes(ymin = ci_low, ymax = ci_high), alpha = 0.4, color = NA) +
labs(x = expression(bold("Log Forward Predictability")), y = "") +
theme_minimal() +
#theme(legend.position = "none")  +
theme(axis.text.x = element_text(face = "bold", color = "black"),  # x-axis text
axis.text.y = element_text(face = "bold", color = "black"),  # y-axis text
axis.title.x = element_text(face = "bold", color = "black"),  # x-axis title
axis.title.y = element_text(face = "bold", color = "black"),  # y-axis title
plot.title = element_text(face = "bold", color = "black"),
legend.title = element_text(face = "bold"))
p3 <- ggplot(deltaBwPred_class, aes(x = delta_bwPred, y = predicted, color = Class, fill = Class)) +
geom_line() +
geom_ribbon(aes(ymin = ci_low, ymax = ci_high), alpha = 0.4, color = NA) +
labs(x = expression(bold("Delta Backward Predictability")), y = "") +
theme_minimal() +
#theme(legend.position = "none")  +
theme(axis.text.x = element_text(face = "bold", color = "black"),  # x-axis text
axis.text.y = element_text(face = "bold", color = "black"),  # y-axis text
axis.title.x = element_text(face = "bold", color = "black"),  # x-axis title
axis.title.y = element_text(face = "bold", color = "black"),  # y-axis title
plot.title = element_text(face = "bold", color = "black"),
legend.title = element_text(face = "bold"))
p4 <- ggplot(condPMI_class, aes(x = condPMI, y = predicted, color = Class, fill = Class)) +
geom_line() +
geom_ribbon(aes(ymin = ci_low, ymax = ci_high), alpha = 0.4, color = NA) +
labs(x = expression(bold("Conditional PMI")), y = "") +
theme_minimal() +
#theme(legend.position = "none")  +
theme(axis.text.x = element_text(face = "bold", color = "black"),  # x-axis text
axis.text.y = element_text(face = "bold", color = "black"),  # y-axis text
axis.title.x = element_text(face = "bold", color = "black"),  # x-axis title
axis.title.y = element_text(face = "bold", color = "black"),  # y-axis title
plot.title = element_text(face = "bold", color = "black"),
legend.title = element_text(face = "bold"))
condPMI_class <- predict_interaction_with_ci(
model = m.FuncContentDist.mainEffect.condPMI ,
x_var = "condPMI",
group_var = "Class"
)
m.FuncContentDist.int.condPMI <- lmer(duration * 1000 ~ word_len + uttrSR + age + sex + unigram_logProb * Class + infillFw_logProb * Class + condPMI * Class + (1|speaker_id), data = scores)
summary(m.FuncContentDist.int.condPMI)
condPMI_class <- predict_interaction_with_ci(
model = m.FuncContentDist.mainEffect.condPMI ,
x_var = "condPMI",
group_var = "Class"
)
m.FuncContentDist.mainEffect.condPMI<- lmer(duration * 1000 ~ word_len + uttrSR + age + sex + unigram_logProb + infillFw_logProb + condPMI  + Class + (1|speaker_id), data = scores)
condPMI_class <- predict_interaction_with_ci(
model = m.FuncContentDist.mainEffect.condPMI ,
x_var = "condPMI",
group_var = "Class"
)
p4 <- ggplot(condPMI_class, aes(x = condPMI, y = predicted, color = Class, fill = Class)) +
geom_line() +
geom_ribbon(aes(ymin = ci_low, ymax = ci_high), alpha = 0.4, color = NA) +
labs(x = expression(bold("Conditional PMI")), y = "") +
theme_minimal() +
#theme(legend.position = "none")  +
theme(axis.text.x = element_text(face = "bold", color = "black"),  # x-axis text
axis.text.y = element_text(face = "bold", color = "black"),  # y-axis text
axis.title.x = element_text(face = "bold", color = "black"),  # x-axis title
axis.title.y = element_text(face = "bold", color = "black"),  # y-axis title
plot.title = element_text(face = "bold", color = "black"),
legend.title = element_text(face = "bold"))
saveRDS(p4,'plots/rds/interaction_plot_PMI.rds')
# save plots
saveRDS(p1,'plots/rds/interaction_plot_freq.rds')
saveRDS(p2,'plots/rds/interaction_plot_fwPred.rds')
saveRDS(p3,'plots/rds/interaction_plot_bwPred.rds')
# interaction plots
int.plot1 <- readRDS('plots/RDS/interaction_plot_freq.rds')
int.plot2 <- readRDS('plots/RDS/interaction_plot_fwPred.rds')
int.plot3 <- readRDS('plots/RDS/interaction_plot_bwPred.rds')
int.plot4 <- readRDS('plots/RDS/interaction_plot_PMI.rds')
plt.combined <- (int.plot1  + int.plot2) / (int.plot3 + int.plot4)
plt.combined
# interaction plots
int.plot1 <- readRDS('plots/RDS/interaction_plot_freq.rds')
int.plot1 + theme(axis.title.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.x  = element_blank(),
axis.title.y = element_blank(),
legend.position = "none")
# interaction plots
int.plot1 <- readRDS('plots/RDS/interaction_plot_freq.rds')
int.plot1 <- int.plot1 + theme(axis.title.x = element_blank(),
axis.ticks.x = element_blank(),
axis.text.x  = element_blank(),
axis.title.y = element_blank(),
legend.position = "none")
plt.combined <- (int.plot1  + int.plot2) / (int.plot3 + int.plot4)
plt.combined
# interaction plots
int.plot1 <- readRDS('plots/RDS/interaction_plot_freq.rds')
int.plot1 <- int.plot1 + theme(legend.position = "none")
int.plot2 <- int.plot2 + theme(legend.position = "none")
# interaction plots
int.plot1 <- readRDS('plots/RDS/interaction_plot_freq.rds')
int.plot1 <- int.plot1 + theme(legend.position = "none")
int.plot2 <- readRDS('plots/RDS/interaction_plot_fwPred.rds')
int.plot3 <- readRDS('plots/RDS/interaction_plot_bwPred.rds')
int.plot3 <- int.plot3 + theme(legend.position = "none")
int.plot4 <- readRDS('plots/RDS/interaction_plot_PMI.rds')
int.plot4 <- int.plot4 + theme(legend.position = "none")
plt.combined <- (int.plot1  + int.plot2) / (int.plot3 + int.plot4)
plt.combined
library(tidyverse)
library(lme4)
library(ggsignif)
library(ggpubr)
library(lmtest)
library(patchwork)
library(cowplot)
library(emmeans)
library(relaimpo)
library(partR2)
library(ggeffects)
library(lmerTest)
library(dominanceanalysis)
# interaction plots
int.plot1 <- readRDS('plots/RDS/interaction_plot_freq.rds')
int.plot1 <- int.plot1 + theme(legend.position = "none")
int.plot2 <- readRDS('plots/RDS/interaction_plot_fwPred.rds')
int.plot3 <- readRDS('plots/RDS/interaction_plot_bwPred.rds')
int.plot3 <- int.plot3 + theme(legend.position = "none")
+ xlab("Relative Backward Predictability")
library(tidyverse)
library(lme4)
library(ggsignif)
library(ggpubr)
library(lmtest)
library(patchwork)
library(cowplot)
library(emmeans)
library(relaimpo)
library(partR2)
library(ggeffects)
library(lmerTest)
library(dominanceanalysis)
# interaction plots
int.plot1 <- readRDS('plots/RDS/interaction_plot_freq.rds')
int.plot1 <- int.plot1 + theme(legend.position = "none")
int.plot2 <- readRDS('plots/RDS/interaction_plot_fwPred.rds')
int.plot3 <- readRDS('plots/RDS/interaction_plot_bwPred.rds')
int.plot3 <- int.plot3 + theme(legend.position = "none") +
+ xlab("Relative Backward Predictability")
int.plot3 <- int.plot3 + theme(legend.position = "none") +
+ xlab("Relative Backward Predictability")
int.plot3 <- int.plot3 + theme(legend.position = "none")
int.plot4 <- readRDS('plots/RDS/interaction_plot_PMI.rds')
int.plot4 <- int.plot4 + theme(legend.position = "none")
plt.combined <- (int.plot1  + int.plot2) / (int.plot3 + int.plot4)
plt.combined
int.plot3 <- int.plot3 + theme(legend.position = "none") +
xlab("Relative Backward Predictability")
int.plot4 <- readRDS('plots/RDS/interaction_plot_PMI.rds')
int.plot4 <- int.plot4 + theme(legend.position = "none")
plt.combined <- (int.plot1  + int.plot2) / (int.plot3 + int.plot4)
plt.combined
plt.combined <- (int.plot1  + int.plot2) / (int.plot3 + int.plot4) +
plot_annotation(
title = NULL,
theme = theme(
plot.margin = margin(10, 10, 10, 40) # room on the left
)
) &
labs(y = "Predicted Duration (ms)")
plt.combined
plt.combined <- (int.plot1  + int.plot2) / (int.plot3 + int.plot4) +
grid.newpage()
grid.draw(ggplotGrob(plt.combined))
grid.text("Predicted Duration (ms)", x = 0.02, y = 0.5, rot = 90,
gp = gpar(fontsize = 14, fontface = "bold"))
plt.combined
library(grid)
plt.combined <- (int.plot1  + int.plot2) / (int.plot3 + int.plot4) +
grid.newpage()
grid.draw(ggplotGrob(plt.combined))
grid.text("Predicted Duration (ms)", x = 0.02, y = 0.5, rot = 90,
gp = gpar(fontsize = 14, fontface = "bold"))
plt.combined <- (int.plot1  + int.plot2) / (int.plot3 + int.plot4) +
p_grob <- patchworkGrob(plt.combined)
# draw both together
grid.newpage()
plt.combined <- (int.plot1  + int.plot2) / (int.plot3 + int.plot4) +
p_grob <- patchworkGrob(plt.combined)
